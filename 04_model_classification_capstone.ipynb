{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone Project: Classification Model <br>\n",
    "\n",
    "#### Brandie Hatch\n",
    "\n",
    "### Modeling\n",
    "\n",
    "- Imports, Data Reading, Model Prep\n",
    "- Modeling\n",
    "- Model Evaluation\n",
    "\n",
    "#### Modeling:\n",
    "Supervised Classification - likely a combination of Logistic Regression, Random Forest, Decision Trees, Naive Bayes, and SVM to see which one performs the best at accurately predicting male or female based on education attainment, labor types, income, etc. Then, use that type of model to get the best results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports, Data Reading, and Model Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python library imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import plot_tree, DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix, ConfusionMatrixDisplay, plot_roc_curve, roc_auc_score, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.svm import LinearSVC, SVC \n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.manifold import MDS\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "pd.options.display.max_columns =999\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3239553, 26)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGEP</th>\n",
       "      <th>CIT</th>\n",
       "      <th>COW</th>\n",
       "      <th>ENG</th>\n",
       "      <th>ESR</th>\n",
       "      <th>FFSP</th>\n",
       "      <th>LANX</th>\n",
       "      <th>MAR</th>\n",
       "      <th>MULTG</th>\n",
       "      <th>NOC</th>\n",
       "      <th>OCCP</th>\n",
       "      <th>PINCP</th>\n",
       "      <th>POVPIP</th>\n",
       "      <th>RAC1P</th>\n",
       "      <th>SCH</th>\n",
       "      <th>SCHG</th>\n",
       "      <th>SCHL</th>\n",
       "      <th>SCIENGP</th>\n",
       "      <th>SCIENGRLP</th>\n",
       "      <th>SEMP</th>\n",
       "      <th>SEX</th>\n",
       "      <th>WAGP</th>\n",
       "      <th>WKEXREL</th>\n",
       "      <th>WKL</th>\n",
       "      <th>WRK</th>\n",
       "      <th>STATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>6250</td>\n",
       "      <td>63000</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>63000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>4740</td>\n",
       "      <td>2000</td>\n",
       "      <td>-1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>110</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>4110</td>\n",
       "      <td>6000</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AGEP  CIT  COW  ENG  ESR  FFSP  LANX  MAR  MULTG  NOC  OCCP  PINCP  POVPIP  \\\n",
       "0    35    1    1    0    6     0     2    1      0   -1  6250  63000      -1   \n",
       "1    25    1    0    0    6     0     2    5      0   -1     9      0      -1   \n",
       "2    21    5    2    0    1     0     2    5      0   -1  4740   2000      -1   \n",
       "3    49    1    1    0    6     0     2    3      0   -1   110      0      -1   \n",
       "4    18    1    1    0    6     0     2    5      0   -1  4110   6000      -1   \n",
       "\n",
       "   RAC1P  SCH  SCHG  SCHL  SCIENGP  SCIENGRLP  SEMP  SEX   WAGP  WKEXREL  WKL  \\\n",
       "0      1    1     0    17        0          0     0    1  63000        0    1   \n",
       "1      1    1     0    12        0          0     0    1      0        0    3   \n",
       "2      6    3    15    19        0          0     0    2   2000        0    1   \n",
       "3      1    1     0    21        1          2     0    1      0        0    2   \n",
       "4      1    2    15    16        0          0     0    2   6000        0    1   \n",
       "\n",
       "   WRK  STATE  \n",
       "0    0     18  \n",
       "1    0     48  \n",
       "2    0     18  \n",
       "3    0      4  \n",
       "4    2      6  "
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in Data\n",
    "\n",
    "df = pd.read_csv('./data/data_clean.csv', index_col=False)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 26)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGEP</th>\n",
       "      <th>CIT</th>\n",
       "      <th>COW</th>\n",
       "      <th>ENG</th>\n",
       "      <th>ESR</th>\n",
       "      <th>FFSP</th>\n",
       "      <th>LANX</th>\n",
       "      <th>MAR</th>\n",
       "      <th>MULTG</th>\n",
       "      <th>NOC</th>\n",
       "      <th>OCCP</th>\n",
       "      <th>PINCP</th>\n",
       "      <th>POVPIP</th>\n",
       "      <th>RAC1P</th>\n",
       "      <th>SCH</th>\n",
       "      <th>SCHG</th>\n",
       "      <th>SCHL</th>\n",
       "      <th>SCIENGP</th>\n",
       "      <th>SCIENGRLP</th>\n",
       "      <th>SEMP</th>\n",
       "      <th>SEX</th>\n",
       "      <th>WAGP</th>\n",
       "      <th>WKEXREL</th>\n",
       "      <th>WKL</th>\n",
       "      <th>WRK</th>\n",
       "      <th>STATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>27800</td>\n",
       "      <td>136</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>38000</td>\n",
       "      <td>442</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>410</td>\n",
       "      <td>89000</td>\n",
       "      <td>501</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>89000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>96400</td>\n",
       "      <td>501</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>9700</td>\n",
       "      <td>73</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AGEP  CIT  COW  ENG  ESR  FFSP  LANX  MAR  MULTG  NOC  OCCP  PINCP  POVPIP  \\\n",
       "0    49    1    0    0    6     0     2    3      1    2     9  27800     136   \n",
       "1    70    1    0    0    6     0     2    2      1    0     9  38000     442   \n",
       "2    58    1    1    0    1     0     2    1      1    0   410  89000     501   \n",
       "3    76    1    0    0    6     0     2    2      1    0     9  96400     501   \n",
       "4    57    1    0    0    6     0     2    3      1    0     9   9700      73   \n",
       "\n",
       "   RAC1P  SCH  SCHG  SCHL  SCIENGP  SCIENGRLP  SEMP  SEX   WAGP  WKEXREL  WKL  \\\n",
       "0      1    1     0    19        0          0     0    1      0       12    3   \n",
       "1      1    1     0    13        0          0     0    1      0       12    3   \n",
       "2      1    1     0    16        0          0     0    1  89000        1    1   \n",
       "3      1    1     0    21        2          2     0    1      0        0    3   \n",
       "4      1    1     0    16        0          0     0    1      0        0    3   \n",
       "\n",
       "   WRK  STATE  \n",
       "0    2     26  \n",
       "1    2     42  \n",
       "2    1     36  \n",
       "3    2     17  \n",
       "4    2     39  "
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tried modeling, but fit would not work because I do not have enough memory. Tried Google Collab to run the fit, but it also did not have the memory to do the work.\n",
    "# Decided to take my 3 million + observations and reduce them down to a lower number using pandas random sample.\n",
    "# Returns a new object of same type as caller containing n items randomly sampled from the caller object. https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sample.html\n",
    "\n",
    "df = df.sample(n=10000, replace=False, axis=0, ignore_index=True, random_state=42)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns the root mean squared error from y and y predictions of models\n",
    "def rmse(y, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X and y \n",
    "\n",
    "X = df.drop(columns=['SEX', 'FFSP', 'LANX', 'NOC', 'RAC1P', 'SCH', 'SCHG'])\n",
    "y = df['SEX']\n",
    "\n",
    "# Train/Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.3,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "Xs_train = ss.fit_transform(X_train)\n",
    "Xs_test = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    0.5049\n",
       "1    0.4951\n",
       "Name: SEX, dtype: float64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the baseline accuracy (% of the majority class, Male)\n",
    "# benchmark to beat is .509706\n",
    "y.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is my hypothesis for how to make the story work. Then how changes were made"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(Xs_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hatch\\anaconda3\\envs\\dsi-222\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "logreg_y_pred = lr.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7036334272900912"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse(y, logreg_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "gnb.fit(Xs_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hatch\\anaconda3\\envs\\dsi-222\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but GaussianNB was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "gnb_y_pred = gnb.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7120393247567159"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse(y, gnb_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=2, random_state=0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100, max_depth=2, random_state=0)\n",
    "rf.fit(Xs_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hatch\\anaconda3\\envs\\dsi-222\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "rf_y_pred = rf.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7066116330771806"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse(y, rf_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5116666666666667\n",
      "0.49333333333333335\n",
      "0.5013333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hatch\\anaconda3\\envs\\dsi-222\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\hatch\\anaconda3\\envs\\dsi-222\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but GaussianNB was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\hatch\\anaconda3\\envs\\dsi-222\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test, lr.predict(X_test)))\n",
    "print(accuracy_score(y_test, gnb.predict(X_test)))\n",
    "print(accuracy_score(y_test, rf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X and y \n",
    "\n",
    "X = df.drop(columns=['SEX'])\n",
    "y = df['SEX']\n",
    "\n",
    "# Train/Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.3,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGEP</th>\n",
       "      <th>CIT</th>\n",
       "      <th>COW</th>\n",
       "      <th>ENG</th>\n",
       "      <th>ESR</th>\n",
       "      <th>FFSP</th>\n",
       "      <th>LANX</th>\n",
       "      <th>MAR</th>\n",
       "      <th>MULTG</th>\n",
       "      <th>NOC</th>\n",
       "      <th>OCCP</th>\n",
       "      <th>PINCP</th>\n",
       "      <th>POVPIP</th>\n",
       "      <th>RAC1P</th>\n",
       "      <th>SCH</th>\n",
       "      <th>SCHG</th>\n",
       "      <th>SCHL</th>\n",
       "      <th>SCIENGP</th>\n",
       "      <th>SCIENGRLP</th>\n",
       "      <th>SEMP</th>\n",
       "      <th>WAGP</th>\n",
       "      <th>WKEXREL</th>\n",
       "      <th>WKL</th>\n",
       "      <th>WRK</th>\n",
       "      <th>STATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>27800</td>\n",
       "      <td>136</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>38000</td>\n",
       "      <td>442</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>410</td>\n",
       "      <td>89000</td>\n",
       "      <td>501</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>89000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>96400</td>\n",
       "      <td>501</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>9700</td>\n",
       "      <td>73</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AGEP  CIT  COW  ENG  ESR  FFSP  LANX  MAR  MULTG  NOC  OCCP  PINCP  POVPIP  \\\n",
       "0    49    1    0    0    6     0     2    3      1    2     9  27800     136   \n",
       "1    70    1    0    0    6     0     2    2      1    0     9  38000     442   \n",
       "2    58    1    1    0    1     0     2    1      1    0   410  89000     501   \n",
       "3    76    1    0    0    6     0     2    2      1    0     9  96400     501   \n",
       "4    57    1    0    0    6     0     2    3      1    0     9   9700      73   \n",
       "\n",
       "   RAC1P  SCH  SCHG  SCHL  SCIENGP  SCIENGRLP  SEMP   WAGP  WKEXREL  WKL  WRK  \\\n",
       "0      1    1     0    19        0          0     0      0       12    3    2   \n",
       "1      1    1     0    13        0          0     0      0       12    3    2   \n",
       "2      1    1     0    16        0          0     0  89000        1    1    1   \n",
       "3      1    1     0    21        2          2     0      0        0    3    2   \n",
       "4      1    1     0    16        0          0     0      0        0    3    2   \n",
       "\n",
       "   STATE  \n",
       "0     26  \n",
       "1     42  \n",
       "2     36  \n",
       "3     17  \n",
       "4     39  "
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = MDS(n_components=5, random_state=42)\n",
    "X_transformed = embedding.fit_transform(X[:7000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7000, 5)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_transformed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X_transformed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_y_pred = lr.predict(X_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7025463889106743"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse(y_train, logreg_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column transformer, OneHotEncoder is used on the categorical columns to create the same categories in each feature so the array produced will be the same shape as the data used to train the model\n",
    "col_trans = ColumnTransformer([\n",
    "    ('ohe', OneHotEncoder(), ['CIT', 'COW', 'ENG', 'ESR', 'MAR', 'MULTG', 'SCHL', 'WKEXREL', 'WKL', 'WRK', 'STATE']),\n",
    "    ('ss', StandardScaler(), ['AGEP', 'PINCP', 'WAGP'])],\n",
    "    remainder='passthrough',\n",
    "    sparse_threshold=0)\n",
    "\n",
    "\n",
    "#removed 'SEMP' because of this error: ValueError: Found unknown categories [-7000, -380, 100, 220, 3800, 7200, 8800, 9100, 13700, 27000, 31000, 70000, 77000, 324000] in column 7 during transform\n",
    "# may need to go back to creation of X and y before train, test, split to narrow down the columns to just the ones in this cell???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column transformer, OneHotEncoder is used on the categorical columns to create the same categories in each feature so the array produced will be the same shape as the data used to train the model\n",
    "# col_trans = ColumnTransformer([\n",
    "#    ('ohe', OneHotEncoder(), ['CIT', 'COW', 'ENG', 'ESR', 'MAR', 'MULTG', 'SCHL', 'WKEXREL', 'WKL', 'WRK', 'STATE']),\n",
    "#    ('poly', PolynomialFeatures(), ['AGEP', 'PINCP', 'WAGP'])],\n",
    "#    remainder='passthrough',\n",
    "#    sparse_threshold=0)\n",
    "\n",
    "# Attempted to see what would happen if I used PolynomialFeatures instead of StandardScaler. Went back to StandardScaler because results of Polynomial Features were worse.\n",
    "# Accuracy score of 0.50628... for Polynomial Features vs. 0.528571... for StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column transformer, OneHotEncoder is used on the categorical columns to create the same categories in each feature so the array produced will be the same shape as the data used to train the model\n",
    "col_trans = ColumnTransformer([\n",
    "    ('ohe', OneHotEncoder()),\n",
    "    ('ss', StandardScaler())],\n",
    "    remainder='passthrough',\n",
    "    sparse_threshold=3)\n",
    "\n",
    "\n",
    "#removed 'SEMP' because of this error: ValueError: Found unknown categories [-7000, -380, 100, 220, 3800, 7200, 8800, 9100, 13700, 27000, 31000, 70000, 77000, 324000] in column 7 during transform\n",
    "# may need to go back to creation of X and y before train, test, split to narrow down the columns to just the ones in this cell???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline StandardScaler + instantiate Logistic Regression\n",
    "pipe_log = Pipeline([\n",
    "    ('col_trans', col_trans),\n",
    "    ('log_reg', LogisticRegression(solver='saga', random_state=42, n_jobs=3, max_iter=10000))\n",
    "])\n",
    "\n",
    "# solver :  Algorithm to use in the optimization problem. Default is 'lbfgs'. To choose a solver, you might want to consider the following aspects: 'sag' and 'saga' are faster for large data sets\n",
    "# increased max_iter to 1000, 2000, 3000, 5000, 10000 because of max iter errors\n",
    "# https://datascience.stackexchange.com/questions/91225/why-gridsearchcv-returns-nan\n",
    "\n",
    "# error saying l1_ratio needed to be between 0 and 1, so added l1_ratio=0.5 to see what happens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_log = {\n",
    "    'log_reg__penalty': ['l2'],\n",
    "    'log_reg__C': [0.0001, 0.001, .01]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = ['accuracy', 'precision', 'recall', 'f1']\n",
    "log_gs = GridSearchCV(pipe_log, param_grid=params_log, scoring = scoring, refit='accuracy', error_score='raise', cv=5)\n",
    "\n",
    "# add scoring f1 because of  \"UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan\"\n",
    "# SCORING = ['accuracy', 'precision', 'recall', 'f1' ]  ---want to add\n",
    "# https://scikit-learn.org/stable/modules/model_evaluation.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12144/3862456488.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlog_gs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_transformed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\hatch\\anaconda3\\envs\\dsi-222\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    889\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 891\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    892\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[1;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\hatch\\anaconda3\\envs\\dsi-222\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1390\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1391\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1392\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1393\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1394\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\hatch\\anaconda3\\envs\\dsi-222\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    836\u001b[0m                     )\n\u001b[0;32m    837\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 838\u001b[1;33m                 out = parallel(\n\u001b[0m\u001b[0;32m    839\u001b[0m                     delayed(_fit_and_score)(\n\u001b[0;32m    840\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\hatch\\anaconda3\\envs\\dsi-222\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1041\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1043\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1044\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1045\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\hatch\\anaconda3\\envs\\dsi-222\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    859\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    860\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 861\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    862\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    863\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\hatch\\anaconda3\\envs\\dsi-222\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    777\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\hatch\\anaconda3\\envs\\dsi-222\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\hatch\\anaconda3\\envs\\dsi-222\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\hatch\\anaconda3\\envs\\dsi-222\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\hatch\\anaconda3\\envs\\dsi-222\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\hatch\\anaconda3\\envs\\dsi-222\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    214\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\hatch\\anaconda3\\envs\\dsi-222\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    666\u001b[0m             \u001b[0mcloned_parameters\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msafe\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    667\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 668\u001b[1;33m         \u001b[0mestimator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mcloned_parameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    669\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    670\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\hatch\\anaconda3\\envs\\dsi-222\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mset_params\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    186\u001b[0m             \u001b[0mPipeline\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0minstance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m         \"\"\"\n\u001b[1;32m--> 188\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"steps\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    189\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\hatch\\anaconda3\\envs\\dsi-222\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\u001b[0m in \u001b[0;36m_set_params\u001b[1;34m(self, attr, **params)\u001b[0m\n\u001b[0;32m     52\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_replace_estimator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m         \u001b[1;31m# 3. Step parameters and other initialisation arguments\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\hatch\\anaconda3\\envs\\dsi-222\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mset_params\u001b[1;34m(self, **params)\u001b[0m\n\u001b[0;32m    237\u001b[0m             \u001b[1;31m# Simple optimization to gain speed (inspect is slow)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    238\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 239\u001b[1;33m         \u001b[0mvalid_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m         \u001b[0mnested_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# grouped by prefix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\hatch\\anaconda3\\envs\\dsi-222\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mget_params\u001b[1;34m(self, deep)\u001b[0m\n\u001b[0;32m    165\u001b[0m             \u001b[0mParameter\u001b[0m \u001b[0mnames\u001b[0m \u001b[0mmapped\u001b[0m \u001b[0mto\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m         \"\"\"\n\u001b[1;32m--> 167\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"steps\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdeep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdeep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    168\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mset_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\hatch\\anaconda3\\envs\\dsi-222\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\u001b[0m in \u001b[0;36m_get_params\u001b[1;34m(self, attr, deep)\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mestimator\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mestimators\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"get_params\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m                 \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m                     \u001b[0mout\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"%s__%s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\hatch\\anaconda3\\envs\\dsi-222\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\u001b[0m in \u001b[0;36mget_params\u001b[1;34m(self, deep)\u001b[0m\n\u001b[0;32m    250\u001b[0m             \u001b[0mParameter\u001b[0m \u001b[0mnames\u001b[0m \u001b[0mmapped\u001b[0m \u001b[0mto\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m         \"\"\"\n\u001b[1;32m--> 252\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"_transformers\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdeep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdeep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    253\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mset_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\hatch\\anaconda3\\envs\\dsi-222\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\u001b[0m in \u001b[0;36m_get_params\u001b[1;34m(self, attr, deep)\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mdeep\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m         \u001b[0mestimators\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m         \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimators\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mestimator\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mestimators\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\hatch\\anaconda3\\envs\\dsi-222\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\u001b[0m in \u001b[0;36m_transformers\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[0mof\u001b[0m \u001b[0mtuples\u001b[0m \u001b[0mof\u001b[0m \u001b[0mlen\u001b[0m \u001b[1;36m2.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m         \"\"\"\n\u001b[1;32m--> 225\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrans\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrans\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransformers\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0m_transformers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\hatch\\anaconda3\\envs\\dsi-222\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[0mof\u001b[0m \u001b[0mtuples\u001b[0m \u001b[0mof\u001b[0m \u001b[0mlen\u001b[0m \u001b[1;36m2.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m         \"\"\"\n\u001b[1;32m--> 225\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrans\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrans\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransformers\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0m_transformers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 2)"
     ]
    }
   ],
   "source": [
    "log_gs.fit(X_transformed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5285714285714286\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'log_reg__C': 0.001, 'log_reg__penalty': 'l2'}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(log_gs.best_score_)\n",
    "log_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5275714285714286, 0.5293333333333333)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_gs.score(X_train, y_train), log_gs.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    1621\n",
       "1    1379\n",
       "dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(log_gs.predict(X_test)).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation & Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix Displays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 504x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Logisitic Regression\n",
    "fig, ax = plt.subplots(figsize=(7, 5))\n",
    "ConfusionMatrixDisplay.from_estimator(log_gs,\n",
    "                                      X_test,\n",
    "                                      y_test,\n",
    "                                      display_labels=['Male', 'Female'], \n",
    "                                      cmap='Reds', \n",
    "                                      ax=ax);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "0.5289328932893289\n"
     ]
    }
   ],
   "source": [
    "# ROC Accuracy score\n",
    "print('Logistic Regression')\n",
    "print(roc_auc_score(y_test, log_gs.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "0.5285714285714286\n",
      "{'log_reg__C': 0.001, 'log_reg__penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "print('Logistic Regression')\n",
    "print(log_gs.best_score_)\n",
    "print(log_gs.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "0.5293333333333333\n"
     ]
    }
   ],
   "source": [
    "# Accuracy score\n",
    "print('Logistic Regression')\n",
    "print(accuracy_score(y_test, log_gs.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "0.5264684554024656\n"
     ]
    }
   ],
   "source": [
    "# Precision score\n",
    "print('Logistic Regression')\n",
    "print(precision_score(y_test, log_gs.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "0.4888888888888889\n"
     ]
    }
   ],
   "source": [
    "# Recall score\n",
    "print('Logistic Regression')\n",
    "print(recall_score(y_test, log_gs.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "0.4888888888888889\n"
     ]
    }
   ],
   "source": [
    "# Specificity score\n",
    "print('Logistic Regression')\n",
    "print(recall_score(y_test, log_gs.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n"
     ]
    },
    {
     "ename": "NotFittedError",
     "evalue": "This GridSearchCV instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12144/2567664253.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# F1 score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Logistic Regression'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog_gs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\hatch\\anaconda3\\envs\\dsi-222\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m             \u001b[1;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# noqa\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    114\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\hatch\\anaconda3\\envs\\dsi-222\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    518\u001b[0m             \u001b[0mthe\u001b[0m \u001b[0mbest\u001b[0m \u001b[0mfound\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    519\u001b[0m         \"\"\"\n\u001b[1;32m--> 520\u001b[1;33m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    521\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    522\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\hatch\\anaconda3\\envs\\dsi-222\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[1;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[0;32m   1220\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1221\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mfitted\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1222\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"name\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1223\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1224\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFittedError\u001b[0m: This GridSearchCV instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "# F1 score\n",
    "print('Logistic Regression')\n",
    "print(f1_score(y_test, log_gs.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.504857142857143 1.505\n"
     ]
    }
   ],
   "source": [
    "print(y_train.mean(), y_test.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.505"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.sum()/y_test.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    0.505\n",
       "1    0.495\n",
       "Name: SEX, dtype: float64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer Problem, Conclusions, and Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Answer based on the following conclusions:__ Overall, the Logistic Regression model was the best model to identify Service Dogs vs Dog Training Subreddits. The SVM: C-Support Vector Classification model could also be used since it was very close in a lot of ways also. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Variable | Model                                | Best Score (gridsearch) | Train Score       | Test Score        | Accuracy          | ROC Accuracy      | Precision         | Recall            | Specificity       | F1 Score          |\n",
    "|----------|--------------------------------------|-------------------------|-------------------|-------------------|-------------------|-------------------|-------------------|-------------------|-------------------|-------------------|\n",
    "| gs       | Random Forest Classifier             | 0.952763058289175       | 1.000000000000000 | 0.953020134228187 | 0.953020134228187 | 0.953012220770418 | 0.946453407510431 | 0.960479887085391 | 0.945544554455445 | 0.953415061295972 |\n",
    "| tree_gs  | Decision Tree Classifier             | 0.953217259651779       | 1.000000000000000 | 0.949134581419993 | 0.949134581419993 | 0.949132278385616 | 0.947294448348559 | 0.951305575158786 | 0.946958981612447 | 0.949295774647887 |\n",
    "| log_gs   | Logistic Regression                  | 0.965480696442089       | 0.999848599545798 | 0.967855881314023 | 0.967855881314023 | 0.967844989963256 | 0.958506224066390 | 0.978122794636556 | 0.957567185289957 | 0.968215158924205 |\n",
    "| gs_svm   | SVM: Linear SVC                      | 0.960938682816048       | 1.000000000000000 | 0.962910632285411 | 0.962910632285411 | 0.962901981296022 | 0.955555555555555 | 0.971065631616090 | 0.954738330975954 | 0.963248162408120 |\n",
    "| gs_svc   | SVM: C-Support Vector Classification | 0.899621498864496       | 0.933080999242997 | 0.914517838219710 | 0.914517838219710 | 0.914575387370373 | 0.965162311955661 | 0.860268172194777 | 0.968882602545968 | 0.909701492537313 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Difference between the Train Score and Test Score of the SVM: C-Support Vector Classification \n",
    "0.933080999242997 - 0.914517838219710"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Difference between the Train Score and Test Score of the Logistic Regression model\n",
    "0.999848599545798 - 0.967855881314023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Findings\n",
    "\n",
    "__Bias/Variance Tradeoff__ All of the models were overfit where the train score was higher than the test score. The *Logistic Regression* model was the least overfit and performed the best in the tradeoff because it had the highest train/test scores. The *SVM: C-Support Vector Classification* was a close second because the difference between the train and test scores was the lowest. <br>  \n",
    "\n",
    "__Accuracy__ Number of correct predictions divided by the total number of predications, multiplied by 100 to get percentage: *Logistic Regression* had the best accuracy because it predicted the correct Subreddit 96.7% of the time. This is a reliable indicator because of the basically even class distribution.<br>\n",
    "\n",
    "__Precision__ Number of true positives divided by the number of true positives plus the false positives: *SVM: C-Support Vector Classification* had the best precision with 96.1% precisely predicted the correct Subreddit. This is not the best indicator because of the even class distribution. Precision in this situation is showing us how many submissions that were predicted as being correct and actually were correct.<br>\n",
    "\n",
    "__Recall__ Fraction of samples from a class which are correctly predicted by the model: *Logistic Regression* had the best recall because of the correctly labeled Subreddits, the model predicted 97.8% correct. <br>\n",
    "\n",
    "__Specificity__ Fraction of samples from a class which are incorrectly predicted as incorrect (True negative rate): *SVM: C-Support Vector Classification* had the best recall because of the incorrectly labeled Subreddits, the model predicted those correctly incorrect at 96.8%. This is not a reliable indicator in this specific situation. <br>\n",
    "\n",
    "__F1 Score__ Combination of precision and recall to check on the balance of the two: *Logistic Regression* has the highest F1 Score, so therefore, is the most balanced of the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Roc Curve for Logistic Regression\n",
    "plot_roc_curve(log_gs, X_test, y_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Roc Curve for Logistic Regression\n",
    "plot_roc_curve(gs_svc, X_test, y_test);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommendations\n",
    "\n",
    "__Implications__ Even though the Logistic Regression model was the most accurate at predicting the difference between the Service Dogs and Dog Training Subreddits, the classifications offered little to help predict training opportunities for service and other dogs. Classification opportunities could be to look more into the most common words and compare the differences between each Subreddit. <br>\n",
    "\n",
    "__Next Steps__ Specifically looking for training theories and pedagogy related words could be a valuable opportunity in the future.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/20-popular-machine-learning-metrics-part-1-classification-regression-evaluation-metrics-1ca3e282a2ce"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ec913dcbef39c008784dc6fe095f00003c17434557640291833f1bcf12636147"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('dsi-222')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
