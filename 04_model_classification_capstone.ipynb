{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone Project: Classification Model <br>\n",
    "\n",
    "#### Brandie Hatch\n",
    "\n",
    "### Modeling\n",
    "\n",
    "- Imports, Data Reading, Model Prep\n",
    "- Modeling\n",
    "- Model Evaluation\n",
    "\n",
    "#### Performing two types of models:\n",
    "1. Clustering / k-Means to see if there are any interesting patterns in the data\n",
    "2. Supervised Classification - likely a combination of Logistic Regression, Random Forest, Decision Trees, Naive Bayes, and SVM to see which one performs the best at accurately predicting male or female based on education attainment, labor types, income, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports, Data Reading, and Model Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python library imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import plot_tree, DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix, ConfusionMatrixDisplay, plot_roc_curve, roc_auc_score, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.svm import LinearSVC, SVC \n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "pd.options.display.max_columns =999\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3239553, 26)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGEP</th>\n",
       "      <th>CIT</th>\n",
       "      <th>COW</th>\n",
       "      <th>ENG</th>\n",
       "      <th>ESR</th>\n",
       "      <th>FFSP</th>\n",
       "      <th>LANX</th>\n",
       "      <th>MAR</th>\n",
       "      <th>MULTG</th>\n",
       "      <th>NOC</th>\n",
       "      <th>OCCP</th>\n",
       "      <th>PINCP</th>\n",
       "      <th>POVPIP</th>\n",
       "      <th>RAC1P</th>\n",
       "      <th>SCH</th>\n",
       "      <th>SCHG</th>\n",
       "      <th>SCHL</th>\n",
       "      <th>SCIENGP</th>\n",
       "      <th>SCIENGRLP</th>\n",
       "      <th>SEMP</th>\n",
       "      <th>SEX</th>\n",
       "      <th>WAGP</th>\n",
       "      <th>WKEXREL</th>\n",
       "      <th>WKL</th>\n",
       "      <th>WRK</th>\n",
       "      <th>STATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>6250</td>\n",
       "      <td>63000</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>63000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>4740</td>\n",
       "      <td>2000</td>\n",
       "      <td>-1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>110</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>4110</td>\n",
       "      <td>6000</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AGEP  CIT  COW  ENG  ESR  FFSP  LANX  MAR  MULTG  NOC  OCCP  PINCP  POVPIP  \\\n",
       "0    35    1    1    0    6     0     2    1      0   -1  6250  63000      -1   \n",
       "1    25    1    0    0    6     0     2    5      0   -1     9      0      -1   \n",
       "2    21    5    2    0    1     0     2    5      0   -1  4740   2000      -1   \n",
       "3    49    1    1    0    6     0     2    3      0   -1   110      0      -1   \n",
       "4    18    1    1    0    6     0     2    5      0   -1  4110   6000      -1   \n",
       "\n",
       "   RAC1P  SCH  SCHG  SCHL  SCIENGP  SCIENGRLP  SEMP  SEX   WAGP  WKEXREL  WKL  \\\n",
       "0      1    1     0    17        0          0     0    1  63000        0    1   \n",
       "1      1    1     0    12        0          0     0    1      0        0    3   \n",
       "2      6    3    15    19        0          0     0    2   2000        0    1   \n",
       "3      1    1     0    21        1          2     0    1      0        0    2   \n",
       "4      1    2    15    16        0          0     0    2   6000        0    1   \n",
       "\n",
       "   WRK  STATE  \n",
       "0    0     18  \n",
       "1    0     48  \n",
       "2    0     18  \n",
       "3    0      4  \n",
       "4    2      6  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in Data\n",
    "\n",
    "df = pd.read_csv('./data/data_clean.csv', index_col=False)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 26)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGEP</th>\n",
       "      <th>CIT</th>\n",
       "      <th>COW</th>\n",
       "      <th>ENG</th>\n",
       "      <th>ESR</th>\n",
       "      <th>FFSP</th>\n",
       "      <th>LANX</th>\n",
       "      <th>MAR</th>\n",
       "      <th>MULTG</th>\n",
       "      <th>NOC</th>\n",
       "      <th>OCCP</th>\n",
       "      <th>PINCP</th>\n",
       "      <th>POVPIP</th>\n",
       "      <th>RAC1P</th>\n",
       "      <th>SCH</th>\n",
       "      <th>SCHG</th>\n",
       "      <th>SCHL</th>\n",
       "      <th>SCIENGP</th>\n",
       "      <th>SCIENGRLP</th>\n",
       "      <th>SEMP</th>\n",
       "      <th>SEX</th>\n",
       "      <th>WAGP</th>\n",
       "      <th>WKEXREL</th>\n",
       "      <th>WKL</th>\n",
       "      <th>WRK</th>\n",
       "      <th>STATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>27800</td>\n",
       "      <td>136</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>38000</td>\n",
       "      <td>442</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>410</td>\n",
       "      <td>89000</td>\n",
       "      <td>501</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>89000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>96400</td>\n",
       "      <td>501</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>9700</td>\n",
       "      <td>73</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AGEP  CIT  COW  ENG  ESR  FFSP  LANX  MAR  MULTG  NOC  OCCP  PINCP  POVPIP  \\\n",
       "0    49    1    0    0    6     0     2    3      1    2     9  27800     136   \n",
       "1    70    1    0    0    6     0     2    2      1    0     9  38000     442   \n",
       "2    58    1    1    0    1     0     2    1      1    0   410  89000     501   \n",
       "3    76    1    0    0    6     0     2    2      1    0     9  96400     501   \n",
       "4    57    1    0    0    6     0     2    3      1    0     9   9700      73   \n",
       "\n",
       "   RAC1P  SCH  SCHG  SCHL  SCIENGP  SCIENGRLP  SEMP  SEX   WAGP  WKEXREL  WKL  \\\n",
       "0      1    1     0    19        0          0     0    1      0       12    3   \n",
       "1      1    1     0    13        0          0     0    1      0       12    3   \n",
       "2      1    1     0    16        0          0     0    1  89000        1    1   \n",
       "3      1    1     0    21        2          2     0    1      0        0    3   \n",
       "4      1    1     0    16        0          0     0    1      0        0    3   \n",
       "\n",
       "   WRK  STATE  \n",
       "0    2     26  \n",
       "1    2     42  \n",
       "2    1     36  \n",
       "3    2     17  \n",
       "4    2     39  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tried modeling, but fit would not work because I do not have enough memory. Tried Google Collab to run the fit, but it also did not have the memory to do the work.\n",
    "# Decided to take my 8 million + observations and reduce them down to a lower number using pandas random sample.\n",
    "# Returns a new object of same type as caller containing n items randomly sampled from the caller object. https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sample.html\n",
    "\n",
    "df = df.sample(n=10000, replace=False, axis=0, ignore_index=True, random_state=42)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns the root mean squared error from y and y predictions of models\n",
    "def rmse(y, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X and y \n",
    "\n",
    "X = df.drop(columns=['SEX', 'FFSP', 'LANX', 'NOC', 'RAC1P', 'SCH', 'SCHG'])\n",
    "y = df['SEX']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.3,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "Xs_train = ss.fit_transform(X_train)\n",
    "Xs_test = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    0.5049\n",
       "1    0.4951\n",
       "Name: SEX, dtype: float64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the baseline accuracy (% of the majority class, Male)\n",
    "# benchmark to beat is .509706\n",
    "y.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is my hypothesis for how to make the story work. Then how changes were made"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(Xs_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hatch\\anaconda3\\envs\\dsi-222\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "logreg_y_pred = lr.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7036334272900912"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse(y, logreg_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "gnb.fit(Xs_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hatch\\anaconda3\\envs\\dsi-222\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but GaussianNB was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "gnb_y_pred = gnb.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7120393247567159"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse(y, gnb_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=2, random_state=0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100, max_depth=2, random_state=0)\n",
    "rf.fit(Xs_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hatch\\anaconda3\\envs\\dsi-222\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "rf_y_pred = rf.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7066116330771806"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse(y, rf_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5116666666666667\n",
      "0.49333333333333335\n",
      "0.5013333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hatch\\anaconda3\\envs\\dsi-222\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\hatch\\anaconda3\\envs\\dsi-222\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but GaussianNB was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\hatch\\anaconda3\\envs\\dsi-222\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test, lr.predict(X_test)))\n",
    "print(accuracy_score(y_test, gnb.predict(X_test)))\n",
    "print(accuracy_score(y_test, rf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGEP</th>\n",
       "      <th>CIT</th>\n",
       "      <th>COW</th>\n",
       "      <th>ENG</th>\n",
       "      <th>ESR</th>\n",
       "      <th>MAR</th>\n",
       "      <th>MULTG</th>\n",
       "      <th>OCCP</th>\n",
       "      <th>PINCP</th>\n",
       "      <th>POVPIP</th>\n",
       "      <th>SCHL</th>\n",
       "      <th>SCIENGP</th>\n",
       "      <th>SCIENGRLP</th>\n",
       "      <th>SEMP</th>\n",
       "      <th>WAGP</th>\n",
       "      <th>WKEXREL</th>\n",
       "      <th>WKL</th>\n",
       "      <th>WRK</th>\n",
       "      <th>STATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>27800</td>\n",
       "      <td>136</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>38000</td>\n",
       "      <td>442</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>410</td>\n",
       "      <td>89000</td>\n",
       "      <td>501</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>89000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>96400</td>\n",
       "      <td>501</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>9700</td>\n",
       "      <td>73</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AGEP  CIT  COW  ENG  ESR  MAR  MULTG  OCCP  PINCP  POVPIP  SCHL  SCIENGP  \\\n",
       "0    49    1    0    0    6    3      1     9  27800     136    19        0   \n",
       "1    70    1    0    0    6    2      1     9  38000     442    13        0   \n",
       "2    58    1    1    0    1    1      1   410  89000     501    16        0   \n",
       "3    76    1    0    0    6    2      1     9  96400     501    21        2   \n",
       "4    57    1    0    0    6    3      1     9   9700      73    16        0   \n",
       "\n",
       "   SCIENGRLP  SEMP   WAGP  WKEXREL  WKL  WRK  STATE  \n",
       "0          0     0      0       12    3    2     26  \n",
       "1          0     0      0       12    3    2     42  \n",
       "2          0     0  89000        1    1    1     36  \n",
       "3          2     0      0        0    3    2     17  \n",
       "4          0     0      0        0    3    2     39  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column transformer, OneHotEncoder is used on the categorical columns to create the same categories in each feature so the array produced will be the same shape as the data used to train the model\n",
    "col_trans = ColumnTransformer([\n",
    "    ('ohe', OneHotEncoder(), ['CIT', 'COW', 'ENG', 'ESR', 'MAR', 'MULTG', 'SCHL', 'WKEXREL', 'WKL', 'WRK', 'STATE']),\n",
    "    ('ss', StandardScaler(), ['AGEP', 'PINCP', 'WAGP'])],\n",
    "    remainder='passthrough',\n",
    "    sparse_threshold=0)\n",
    "\n",
    "\n",
    "#removed 'SEMP' because of this error: ValueError: Found unknown categories [-7000, -380, 100, 220, 3800, 7200, 8800, 9100, 13700, 27000, 31000, 70000, 77000, 324000] in column 7 during transform\n",
    "# may need to go back to creation of X and y before train, test, split to narrow down the columns to just the ones in this cell???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline StandardScaler + instantiate Logistic Regression\n",
    "pipe_log = Pipeline([\n",
    "    ('col_trans', col_trans),\n",
    "    ('log_reg', LogisticRegression(solver='saga', l1_ratio=0.5, random_state=42, n_jobs=2, max_iter=10000))\n",
    "])\n",
    "\n",
    "# solver :  Algorithm to use in the optimization problem. Default is 'lbfgs'. To choose a solver, you might want to consider the following aspects: 'sag' and 'saga' are faster for large data sets\n",
    "# increased max_iter to 1000, 2000, 3000, 5000, 10000 because of max iter errors\n",
    "# https://datascience.stackexchange.com/questions/91225/why-gridsearchcv-returns-nan\n",
    "\n",
    "# error saying l1_ratio needed to be between 0 and 1, so added l1_ratio=0.5 to see what happens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_log = {\n",
    "    'log_reg__penalty': ['l2', 'elasticnet'],\n",
    "    'log_reg__C': [1, 2]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = ['accuracy', 'precision', 'recall', 'f1']\n",
    "log_gs = GridSearchCV(pipe_log, param_grid=params_log, scoring = scoring, refit='accuracy', error_score='raise', cv=5)\n",
    "\n",
    "# add scoring f1 because of  \"UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan\"\n",
    "# SCORING = ['accuracy', 'precision', 'recall', 'f1' ]  ---want to add\n",
    "# https://scikit-learn.org/stable/modules/model_evaluation.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hatch\\anaconda3\\envs\\dsi-222\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "c:\\Users\\hatch\\anaconda3\\envs\\dsi-222\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "c:\\Users\\hatch\\anaconda3\\envs\\dsi-222\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "c:\\Users\\hatch\\anaconda3\\envs\\dsi-222\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "c:\\Users\\hatch\\anaconda3\\envs\\dsi-222\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "c:\\Users\\hatch\\anaconda3\\envs\\dsi-222\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "c:\\Users\\hatch\\anaconda3\\envs\\dsi-222\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "c:\\Users\\hatch\\anaconda3\\envs\\dsi-222\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "c:\\Users\\hatch\\anaconda3\\envs\\dsi-222\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "c:\\Users\\hatch\\anaconda3\\envs\\dsi-222\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "c:\\Users\\hatch\\anaconda3\\envs\\dsi-222\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "             estimator=Pipeline(steps=[('col_trans',\n",
       "                                        ColumnTransformer(remainder='passthrough',\n",
       "                                                          sparse_threshold=0,\n",
       "                                                          transformers=[('ohe',\n",
       "                                                                         OneHotEncoder(),\n",
       "                                                                         ['CIT',\n",
       "                                                                          'COW',\n",
       "                                                                          'ENG',\n",
       "                                                                          'ESR',\n",
       "                                                                          'MAR',\n",
       "                                                                          'MULTG',\n",
       "                                                                          'SCHL',\n",
       "                                                                          'WKEXREL',\n",
       "                                                                          'WKL',\n",
       "                                                                          'WRK',\n",
       "                                                                          'STATE']),\n",
       "                                                                        ('ss',\n",
       "                                                                         StandardScaler(),\n",
       "                                                                         ['AGEP',\n",
       "                                                                          'PINCP',\n",
       "                                                                          'WAGP'])])),\n",
       "                                       ('log_reg',\n",
       "                                        LogisticRegression(l1_ratio=0.5,\n",
       "                                                           max_iter=10000,\n",
       "                                                           n_jobs=2,\n",
       "                                                           random_state=42,\n",
       "                                                           solver='saga'))]),\n",
       "             param_grid={'log_reg__C': [1, 2],\n",
       "                         'log_reg__penalty': ['l2', 'elasticnet']},\n",
       "             refit='accuracy',\n",
       "             scoring=['accuracy', 'precision', 'recall', 'f1'])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5285714285714286\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'log_reg__C': 1, 'log_reg__penalty': 'l2'}"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(log_gs.best_score_)\n",
    "log_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5275714285714286, 0.5293333333333333)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_gs.score(X_train, y_train), log_gs.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    1621\n",
       "1    1379\n",
       "dtype: int64"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(log_gs.predict(X_test)).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation & Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix Displays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 504x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Logisitic Regression\n",
    "fig, ax = plt.subplots(figsize=(7, 5))\n",
    "ConfusionMatrixDisplay.from_estimator(log_gs,\n",
    "                                      X_test,\n",
    "                                      y_test,\n",
    "                                      display_labels=['Male', 'Female'], \n",
    "                                      cmap='Reds', \n",
    "                                      ax=ax);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "0.5289328932893289\n"
     ]
    }
   ],
   "source": [
    "# ROC Accuracy score\n",
    "print('Logistic Regression')\n",
    "print(roc_auc_score(y_test, log_gs.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Logistic Regression')\n",
    "print(log_gs.best_score_)\n",
    "print(log_gs.best_params_)\n",
    "print('SVM: Linear SVC')\n",
    "print(gs_svm.best_score_)\n",
    "print(gs_svm.best_params_)\n",
    "print('SVM: C-Support Vector Classification')\n",
    "print(gs_svc.best_score_)\n",
    "print(gs_svc.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy score\n",
    "print('Logistic Regression')\n",
    "print(accuracy_score(y_test, log_gs.predict(X_test)))\n",
    "print('SVM: Linear SVC')\n",
    "print(accuracy_score(y_test, gs_svm.predict(X_test)))\n",
    "print('SVM: C-Support Vector Classification')\n",
    "print(accuracy_score(y_test, gs_svc.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision score\n",
    "print('Logistic Regression')\n",
    "print(precision_score(y_test, log_gs.predict(X_test)))\n",
    "print('SVM: Linear SVC')\n",
    "print(precision_score(y_test, gs_svm.predict(X_test)))\n",
    "print('SVM: C-Support Vector Classification')\n",
    "print(precision_score(y_test, gs_svc.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recall score\n",
    "print('Logistic Regression')\n",
    "print(recall_score(y_test, log_gs.predict(X_test)))\n",
    "print('SVM: Linear SVC')\n",
    "print(recall_score(y_test, gs_svm.predict(X_test)))\n",
    "print('SVM: C-Support Vector Classification')\n",
    "print(recall_score(y_test, gs_svc.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specificity score\n",
    "print('Logistic Regression')\n",
    "print(recall_score(y_test, log_gs.predict(X_test), pos_label=0))\n",
    "print('SVM: Linear SVC')\n",
    "print(recall_score(y_test, gs_svm.predict(X_test), pos_label=0))\n",
    "print('SVM: C-Support Vector Classification')\n",
    "print(recall_score(y_test, gs_svc.predict(X_test), pos_label=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F1 score\n",
    "print('Logistic Regression')\n",
    "print(f1_score(y_test, log_gs.predict(X_test)))\n",
    "print('SVM: Linear SVC')\n",
    "print(f1_score(y_test, gs_svm.predict(X_test)))\n",
    "print('SVM: C-Support Vector Classification')\n",
    "print(f1_score(y_test, gs_svc.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.504857142857143 1.505\n"
     ]
    }
   ],
   "source": [
    "print(y_train.mean(), y_test.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.505"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.sum()/y_test.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    0.505\n",
       "1    0.495\n",
       "Name: SEX, dtype: float64"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer Problem, Conclusions, and Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Answer based on the following conclusions:__ Overall, the Logistic Regression model was the best model to identify Service Dogs vs Dog Training Subreddits. The SVM: C-Support Vector Classification model could also be used since it was very close in a lot of ways also. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Variable | Model                                | Best Score (gridsearch) | Train Score       | Test Score        | Accuracy          | ROC Accuracy      | Precision         | Recall            | Specificity       | F1 Score          |\n",
    "|----------|--------------------------------------|-------------------------|-------------------|-------------------|-------------------|-------------------|-------------------|-------------------|-------------------|-------------------|\n",
    "| gs       | Random Forest Classifier             | 0.952763058289175       | 1.000000000000000 | 0.953020134228187 | 0.953020134228187 | 0.953012220770418 | 0.946453407510431 | 0.960479887085391 | 0.945544554455445 | 0.953415061295972 |\n",
    "| tree_gs  | Decision Tree Classifier             | 0.953217259651779       | 1.000000000000000 | 0.949134581419993 | 0.949134581419993 | 0.949132278385616 | 0.947294448348559 | 0.951305575158786 | 0.946958981612447 | 0.949295774647887 |\n",
    "| log_gs   | Logistic Regression                  | 0.965480696442089       | 0.999848599545798 | 0.967855881314023 | 0.967855881314023 | 0.967844989963256 | 0.958506224066390 | 0.978122794636556 | 0.957567185289957 | 0.968215158924205 |\n",
    "| gs_svm   | SVM: Linear SVC                      | 0.960938682816048       | 1.000000000000000 | 0.962910632285411 | 0.962910632285411 | 0.962901981296022 | 0.955555555555555 | 0.971065631616090 | 0.954738330975954 | 0.963248162408120 |\n",
    "| gs_svc   | SVM: C-Support Vector Classification | 0.899621498864496       | 0.933080999242997 | 0.914517838219710 | 0.914517838219710 | 0.914575387370373 | 0.965162311955661 | 0.860268172194777 | 0.968882602545968 | 0.909701492537313 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Difference between the Train Score and Test Score of the SVM: C-Support Vector Classification \n",
    "0.933080999242997 - 0.914517838219710"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Difference between the Train Score and Test Score of the Logistic Regression model\n",
    "0.999848599545798 - 0.967855881314023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Findings\n",
    "\n",
    "__Bias/Variance Tradeoff__ All of the models were overfit where the train score was higher than the test score. The *Logistic Regression* model was the least overfit and performed the best in the tradeoff because it had the highest train/test scores. The *SVM: C-Support Vector Classification* was a close second because the difference between the train and test scores was the lowest. <br>  \n",
    "\n",
    "__Accuracy__ Number of correct predictions divided by the total number of predications, multiplied by 100 to get percentage: *Logistic Regression* had the best accuracy because it predicted the correct Subreddit 96.7% of the time. This is a reliable indicator because of the basically even class distribution.<br>\n",
    "\n",
    "__Precision__ Number of true positives divided by the number of true positives plus the false positives: *SVM: C-Support Vector Classification* had the best precision with 96.1% precisely predicted the correct Subreddit. This is not the best indicator because of the even class distribution. Precision in this situation is showing us how many submissions that were predicted as being correct and actually were correct.<br>\n",
    "\n",
    "__Recall__ Fraction of samples from a class which are correctly predicted by the model: *Logistic Regression* had the best recall because of the correctly labeled Subreddits, the model predicted 97.8% correct. <br>\n",
    "\n",
    "__Specificity__ Fraction of samples from a class which are incorrectly predicted as incorrect (True negative rate): *SVM: C-Support Vector Classification* had the best recall because of the incorrectly labeled Subreddits, the model predicted those correctly incorrect at 96.8%. This is not a reliable indicator in this specific situation. <br>\n",
    "\n",
    "__F1 Score__ Combination of precision and recall to check on the balance of the two: *Logistic Regression* has the highest F1 Score, so therefore, is the most balanced of the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Roc Curve for Logistic Regression\n",
    "plot_roc_curve(log_gs, X_test, y_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Roc Curve for Logistic Regression\n",
    "plot_roc_curve(gs_svc, X_test, y_test);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommendations\n",
    "\n",
    "__Implications__ Even though the Logistic Regression model was the most accurate at predicting the difference between the Service Dogs and Dog Training Subreddits, the classifications offered little to help predict training opportunities for service and other dogs. Classification opportunities could be to look more into the most common words and compare the differences between each Subreddit. <br>\n",
    "\n",
    "__Next Steps__ Specifically looking for training theories and pedagogy related words could be a valuable opportunity in the future.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/20-popular-machine-learning-metrics-part-1-classification-regression-evaluation-metrics-1ca3e282a2ce"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ec913dcbef39c008784dc6fe095f00003c17434557640291833f1bcf12636147"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('dsi-222')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
